# Load LLM (e.g., Mistral/LLaMA) locally or via Hugging Face API
